{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepSpeechBuild.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papasanimohansrinivas/IndianAccentSpeechRecognition/blob/DeepSpeechModel/DeepSpeechBuild.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mFxki8uDGqtT",
        "colab_type": "code",
        "outputId": "7b0f6785-93c7-4192-96a1-5d681c84557a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone --single-branch --branch DeepSpeechModel https://github.com/papasanimohansrinivas/IndianAccentSpeechRecognition.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IndianAccentSpeechRecognition'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)   \u001b[K\rremote: Counting objects:  22% (2/9)   \u001b[K\rremote: Counting objects:  33% (3/9)   \u001b[K\rremote: Counting objects:  44% (4/9)   \u001b[K\rremote: Counting objects:  55% (5/9)   \u001b[K\rremote: Counting objects:  66% (6/9)   \u001b[K\rremote: Counting objects:  77% (7/9)   \u001b[K\rremote: Counting objects:  88% (8/9)   \u001b[K\rremote: Counting objects: 100% (9/9)   \u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)   \u001b[K\rremote: Compressing objects:  33% (2/6)   \u001b[K\rremote: Compressing objects:  50% (3/6)   \u001b[K\rremote: Compressing objects:  66% (4/6)   \u001b[K\rremote: Compressing objects:  83% (5/6)   \u001b[K\rremote: Compressing objects: 100% (6/6)   \u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 3), reused 9 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  11% (1/9)   \rUnpacking objects:  22% (2/9)   \rUnpacking objects:  33% (3/9)   \rUnpacking objects:  44% (4/9)   \rUnpacking objects:  55% (5/9)   \rUnpacking objects:  66% (6/9)   \rUnpacking objects:  77% (7/9)   \rUnpacking objects:  88% (8/9)   \rUnpacking objects: 100% (9/9)   \rUnpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6QuOHQf0KMCG",
        "colab_type": "code",
        "outputId": "ea744dda-0704-452d-f4a6-e42ce2deac48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mIndianAccentSpeechRecognition\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gTezSZsStv07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp ./IndianAccentSpeechRecognition/installation_script.sh ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTnr3qCsHCNz",
        "colab_type": "code",
        "outputId": "111b4116-8e02-4ec3-c254-3f575353eb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10305
        }
      },
      "cell_type": "code",
      "source": [
        "!bash ./installation_script.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.96.24.32.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "Detected operating system as Ubuntu/bionic.\n",
            "Checking for curl...\n",
            "Detected curl...\n",
            "Checking for gpg...\n",
            "Detected gpg...\n",
            "Running apt-get update... done.\n",
            "Installing apt-transport-https... done.\n",
            "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
            "Importing packagecloud gpg key... done.\n",
            "Running apt-get update... done.\n",
            "\n",
            "The repository is setup! You can now install packages.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 123 not upgraded.\n",
            "Need to get 5,048 kB of archives.\n",
            "After this operation, 12.6 MB of additional disk space will be used.\n",
            "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.7.1 [5,048 kB]\n",
            "Fetched 5,048 kB in 0s (11.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 131327 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.7.1_amd64.deb ...\n",
            "Unpacking git-lfs (2.7.1) ...\n",
            "Setting up git-lfs (2.7.1) ...\n",
            "Git LFS initialized.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Git LFS initialized.\n",
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 10576 (delta 37), reused 52 (delta 30), pack-reused 10497\u001b[K\n",
            "Receiving objects: 100% (10576/10576), 44.99 MiB | 24.25 MiB/s, done.\n",
            "Resolving deltas: 100% (6687/6687), done.\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x559970eec000 @  0x7f3521a2a2a4 0x559934073cef 0x5599340512db 0x559934006863 0x559933fab3db 0x559933fab896 0x559933fc82a1 0x559933fc8839 0x559933fc8d63 0x55993406ca72 0x559933f0fe9b 0x559933ef69a5 0x559933ef7615 0x559933ef667a 0x7f3520d70b97 0x559933ef66ca\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x5599c89dc000 @  0x7f3521a2a2a4 0x559934073cef 0x5599340512db 0x559934006863 0x559933fab3db 0x559933fab896 0x559933fc82a1 0x559933fc8839 0x559933fc8d63 0x55993406ca72 0x559933f0fe9b 0x559933ef69a5 0x559933ef7615 0x559933ef667a 0x7f3520d70b97 0x559933ef66ca\n",
            "Filtering content: 100% (2/2), 1.69 GiB | 38.36 MiB/s, done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 123 not upgraded.\n",
            "Need to get 3,376 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.2 [221 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1 [1,652 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,376 kB in 1s (2,997 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 131362 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.2_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.2) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Uninstalling tensorflow-1.13.1:\n",
            "  Successfully uninstalled tensorflow-1.13.1\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 345.2MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.14.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu) (3.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu) (5.1.3)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.13.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.22.0)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (3.38.0)\n",
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
            "Collecting numpy==1.15.4 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
            "Collecting sox (from -r requirements.txt (line 7))\n",
            "  Downloading https://files.pythonhosted.org/packages/60/a0/5bee540554af8376e0313e462629d95bf2f2bc3c8cb60697aa01254e6cf5/sox-1.3.7-py2.py3-none-any.whl\n",
            "Collecting paramiko>=2.1 (from -r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
            "\u001b[K    100% |████████████████████████████████| 194kB 14.1MB/s \n",
            "\u001b[?25hCollecting python_speech_features (from -r requirements.txt (line 9))\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Collecting pyxdg (from -r requirements.txt (line 10))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/03/12eb9062f43adb94e30f366743cb5c83fd15fef026500cd4de42c7c12280/pyxdg-0.26-py2.py3-none-any.whl (40kB)\n",
            "\u001b[K    100% |████████████████████████████████| 40kB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (2.18.4)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (3.4.4)\n",
            "Collecting attrdict (from -r requirements.txt (line 15))\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (40.8.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (0.6.3)\n",
            "Collecting soundfile (from -r requirements.txt (line 18))\n",
            "  Downloading https://files.pythonhosted.org/packages/68/64/1191352221e2ec90db7492b4bf0c04fd9d2508de67b3f39cbf093cd6bd86/SoundFile-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.3.1)\n",
            "Collecting bcrypt>=3.1.3 (from paramiko>=2.1->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/79/79a4d167a31cc206117d9b396926615fa9c1fdbd52017bcced80937ac501/bcrypt-3.1.6-cp34-abi3-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.6MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1 (from paramiko>=2.1->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
            "\u001b[K    100% |████████████████████████████████| 768kB 22.8MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.5 (from paramiko>=2.1->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.1->-r requirements.txt (line 8)) (0.4.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->-r requirements.txt (line 11)) (4.6.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 13)) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 13)) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 13)) (2.6)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->-r requirements.txt (line 14)) (2.6.9)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (2.1.6)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (0.20.3)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (0.12.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (4.4.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->-r requirements.txt (line 17)) (0.40.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile->-r requirements.txt (line 18)) (1.12.2)\n",
            "Collecting asn1crypto>=0.21.0 (from cryptography>=1.5->paramiko>=2.1->-r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 30.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->-r requirements.txt (line 17)) (0.28.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 18)) (2.19)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "\u001b[31mstable-baselines 2.2.1 requires tensorflow>=1.5.0, which is not installed.\u001b[0m\n",
            "\u001b[31mmagenta 0.3.19 requires tensorflow>=1.12.0, which is not installed.\u001b[0m\n",
            "\u001b[31mfancyimpute 0.4.2 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, sox, bcrypt, pynacl, asn1crypto, cryptography, paramiko, python-speech-features, pyxdg, attrdict, soundfile\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed asn1crypto-0.24.0 attrdict-2.0.1 bcrypt-3.1.6 cryptography-2.6.1 numpy-1.15.4 paramiko-2.4.2 pynacl-1.3.0 python-speech-features-0.6 pyxdg-0.26 soundfile-0.10.2 sox-1.3.7\n",
            "Collecting ds-ctcdecoder==0.5.0a4 from https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.5.0-alpha.4.cpu-ctc/artifacts/public/ds_ctcdecoder-0.5.0a4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[?25l  Downloading https://index.taskcluster.net/v1/task/project.deepspeech.deepspeech.native_client.v0.5.0-alpha.4.cpu-ctc/artifacts/public/ds_ctcdecoder-0.5.0a4-cp36-cp36m-manylinux1_x86_64.whl (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from ds-ctcdecoder==0.5.0a4) (1.15.4)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.5.0a4\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "\n",
            "       USAGE: ./DeepSpeech.py [flags]\n",
            "flags:\n",
            "\n",
            "tensorflow.python.platform.app:\n",
            "  -h,--[no]help: show this help\n",
            "    (default: 'false')\n",
            "  --[no]helpfull: show full help\n",
            "    (default: 'false')\n",
            "  --[no]helpshort: show this help\n",
            "    (default: 'false')\n",
            "\n",
            "util.flags:\n",
            "  --alphabet_config_path: path to the configuration file specifying the alphabet\n",
            "    used by the network. See the comment in data/alphabet.txt for a description\n",
            "    of the format.\n",
            "    (default: 'data/alphabet.txt')\n",
            "  --beam_width: beam width used in the CTC decoder when building candidate\n",
            "    transcriptions\n",
            "    (default: '1024')\n",
            "    (an integer)\n",
            "  --beta1: beta 1 parameter of Adam optimizer\n",
            "    (default: '0.9')\n",
            "    (a number)\n",
            "  --beta2: beta 2 parameter of Adam optimizer\n",
            "    (default: '0.999')\n",
            "    (a number)\n",
            "  --checkpoint_dir: directory in which checkpoints are stored - defaults to\n",
            "    directory \"deepspeech/checkpoints\" within user's data home specified by the\n",
            "    XDG Base Directory Specification\n",
            "    (default: '')\n",
            "  --checkpoint_secs: checkpoint saving interval in seconds\n",
            "    (default: '600')\n",
            "    (an integer)\n",
            "  --coord_host: coordination server host\n",
            "    (default: 'localhost')\n",
            "  --coord_port: coordination server port\n",
            "    (default: '2500')\n",
            "    (an integer)\n",
            "  --coord_retries: number of tries of workers connecting to training coordinator\n",
            "    before failing\n",
            "    (default: '100')\n",
            "    (an integer)\n",
            "  --dev_batch_size: number of elements in a validation batch\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --dev_cached_features_path: comma separated list of files specifying the\n",
            "    dataset used for validation. multiple files will get merged\n",
            "    (default: '')\n",
            "  --dev_files: comma separated list of files specifying the dataset used for\n",
            "    validation. multiple files will get merged\n",
            "    (default: '')\n",
            "  --dropout_rate: dropout rate for feedforward layers\n",
            "    (default: '0.05')\n",
            "    (a number)\n",
            "  --dropout_rate2: dropout rate for layer 2 - defaults to dropout_rate\n",
            "    (default: '-1.0')\n",
            "    (a number)\n",
            "  --dropout_rate3: dropout rate for layer 3 - defaults to dropout_rate\n",
            "    (default: '-1.0')\n",
            "    (a number)\n",
            "  --dropout_rate4: dropout rate for layer 4 - defaults to 0.0\n",
            "    (default: '0.0')\n",
            "    (a number)\n",
            "  --dropout_rate5: dropout rate for layer 5 - defaults to 0.0\n",
            "    (default: '0.0')\n",
            "    (a number)\n",
            "  --dropout_rate6: dropout rate for layer 6 - defaults to dropout_rate\n",
            "    (default: '-1.0')\n",
            "    (a number)\n",
            "  --[no]early_stop: enable early stopping mechanism over validation dataset.\n",
            "    Make sure that dev FLAG is enabled for this to work\n",
            "    (default: 'true')\n",
            "  --earlystop_nsteps: number of steps to consider for early stopping. Loss is\n",
            "    not stored in the checkpoint so when checkpoint is revived it starts the\n",
            "    loss calculation from start at that point\n",
            "    (default: '4')\n",
            "    (an integer)\n",
            "  --epoch: target epoch to train - if negative, the absolute number of\n",
            "    additional epochs will be trained\n",
            "    (default: '75')\n",
            "    (an integer)\n",
            "  --epsilon: epsilon parameter of Adam optimizer\n",
            "    (default: '1e-08')\n",
            "    (a number)\n",
            "  --estop_mean_thresh: mean threshold for loss to determine the condition if\n",
            "    early stopping is required\n",
            "    (default: '0.5')\n",
            "    (a number)\n",
            "  --estop_std_thresh: standard deviation threshold for loss to determine the\n",
            "    condition if early stopping is required\n",
            "    (default: '0.5')\n",
            "    (a number)\n",
            "  --export_batch_size: number of elements per batch on the exported graph\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --export_dir: directory in which exported models are stored - if omitted, the\n",
            "    model won't get exported\n",
            "    (default: '')\n",
            "  --[no]export_tflite: export a graph ready for TF Lite engine\n",
            "    (default: 'false')\n",
            "  --export_version: version number of the exported model\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --[no]fulltrace: if full trace debug info should be generated during training\n",
            "    (default: 'false')\n",
            "  --inter_op_parallelism_threads: number of inter-op parallelism threads - see\n",
            "    tf.ConfigProto for more details\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --intra_op_parallelism_threads: number of intra-op parallelism threads - see\n",
            "    tf.ConfigProto for more details\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --iters_per_worker: number of train or inference iterations per worker before\n",
            "    results are sent back to coordinator\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --job_name: job name - one of localhost (default), worker, ps\n",
            "    (default: 'localhost')\n",
            "  --learning_rate: learning rate of Adam optimizer\n",
            "    (default: '0.001')\n",
            "    (a number)\n",
            "  --limit_dev: maximum number of elements to use from validation set- 0 means no\n",
            "    limit\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --limit_test: maximum number of elements to use from test set- 0 means no\n",
            "    limit\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --limit_train: maximum number of elements to use from train set - 0 means no\n",
            "    limit\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --lm_alpha: the alpha hyperparameter of the CTC decoder. Language Model\n",
            "    weight.\n",
            "    (default: '0.75')\n",
            "    (a number)\n",
            "  --lm_beta: the beta hyperparameter of the CTC decoder. Word insertion weight.\n",
            "    (default: '1.85')\n",
            "    (a number)\n",
            "  --lm_binary_path: path to the language model binary file created with KenLM\n",
            "    (default: 'data/lm/lm.binary')\n",
            "  --lm_trie_path: path to the language model trie file created with\n",
            "    native_client/generate_trie\n",
            "    (default: 'data/lm/trie')\n",
            "  --log_level: log level for console logs - 0: INFO, 1: WARN, 2: ERROR, 3: FATAL\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --[no]log_placement: whether to log device placement of the operators to the\n",
            "    console\n",
            "    (default: 'false')\n",
            "  --[no]log_traffic: log cluster transaction and traffic information during\n",
            "    debug logging\n",
            "    (default: 'false')\n",
            "  --max_to_keep: number of checkpoint files to keep - default value is 5\n",
            "    (default: '5')\n",
            "    (an integer)\n",
            "  --n_hidden: layer width to use when initialising layers\n",
            "    (default: '2048')\n",
            "    (an integer)\n",
            "  --n_steps: how many timesteps to process at once by the export graph, higher\n",
            "    values mean more latency\n",
            "    (default: '16')\n",
            "    (an integer)\n",
            "  --one_shot_infer: one-shot inference mode: specify a wav file and the script\n",
            "    will load the checkpoint and perform inference on it. Disables training,\n",
            "    testing and exporting.\n",
            "    (default: '')\n",
            "  --ps_hosts: parameter servers - comma separated list of hostname:port pairs\n",
            "    (default: '')\n",
            "  --random_seed: default random seed that is used to initialize variables\n",
            "    (default: '4568')\n",
            "    (an integer)\n",
            "  --relu_clip: ReLU clipping value for non-recurrent layers\n",
            "    (default: '20.0')\n",
            "    (a number)\n",
            "  --[no]remove_export: whether to remove old exported models\n",
            "    (default: 'false')\n",
            "  --replicas: total number of replicas - if negative, its absolute value is\n",
            "    multiplied by the number of workers\n",
            "    (default: '-1')\n",
            "    (an integer)\n",
            "  --replicas_to_agg: number of replicas to aggregate - if negative, its absolute\n",
            "    value is multiplied by the number of workers\n",
            "    (default: '-1')\n",
            "    (an integer)\n",
            "  --report_count: number of phrases with lowest WER (best matching) to print out\n",
            "    during a WER report\n",
            "    (default: '10')\n",
            "    (an integer)\n",
            "  --[no]show_progressbar: Show progress for training, validation and testing\n",
            "    processes. Log level should be > 0.\n",
            "    (default: 'true')\n",
            "  --summary_dir: target directory for TensorBoard summaries - defaults to\n",
            "    directory \"deepspeech/summaries\" within user's data home specified by the\n",
            "    XDG Base Directory Specification\n",
            "    (default: '')\n",
            "  --summary_secs: interval in seconds for saving TensorBoard summaries - if 0,\n",
            "    no summaries will be written\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --task_index: index of task within the job - worker with index 0 will be the\n",
            "    chief\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --[no]test: whether to test the network\n",
            "    (default: 'true')\n",
            "  --test_batch_size: number of elements in a test batch\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --test_cached_features_path: comma separated list of files specifying the\n",
            "    dataset used for testing. multiple files will get merged\n",
            "    (default: '')\n",
            "  --test_files: comma separated list of files specifying the dataset used for\n",
            "    testing. multiple files will get merged\n",
            "    (default: '')\n",
            "  --[no]train: whether to train the network\n",
            "    (default: 'true')\n",
            "  --train_batch_size: number of elements in a training batch\n",
            "    (default: '1')\n",
            "    (an integer)\n",
            "  --train_cached_features_path: comma separated list of files specifying the\n",
            "    dataset used for training. multiple files will get merged\n",
            "    (default: '')\n",
            "  --train_files: comma separated list of files specifying the dataset used for\n",
            "    training. multiple files will get merged\n",
            "    (default: '')\n",
            "  --[no]use_seq_length: have sequence_length in the exported graph (will make\n",
            "    tfcompile unhappy)\n",
            "    (default: 'true')\n",
            "  --validation_step: number of epochs we cycle through before validating the\n",
            "    model - 0 means no validation steps\n",
            "    (default: '0')\n",
            "    (an integer)\n",
            "  --worker_hosts: workers - comma separated list of hostname:port pairs\n",
            "    (default: '')\n",
            "\n",
            "absl.flags:\n",
            "  --flagfile: Insert flag definitions from the given file into the command line.\n",
            "    (default: '')\n",
            "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
            "    the command line even if the program does not define a flag with that name.\n",
            "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
            "    format.\n",
            "    (default: '')\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading processedcommonvoice-indianaccents.zip to /content\n",
            "100% 1.50G/1.50G [00:15<00:00, 111MB/s]\n",
            "100% 1.50G/1.50G [00:15<00:00, 103MB/s]\n",
            "Archive:  processedcommonvoice-indianaccents.zip\n",
            "  inflating: indian_accents.tar.gz   \n",
            "--2019-03-24 17:57:12--  https://github.com/mozilla/DeepSpeech/releases/download/v0.4.1/deepspeech-0.4.1-models.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/2c890200-1426-11e9-966e-08f70227c6ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190324T175712Z&X-Amz-Expires=300&X-Amz-Signature=a8d6a9e7bd80cb3d2a6f3177f5df63a2361f24ecfdd003aaa7a5672928ddb706&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.4.1-models.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-03-24 17:57:12--  https://github-production-release-asset-2e65be.s3.amazonaws.com/60273704/2c890200-1426-11e9-966e-08f70227c6ad?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190324%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190324T175712Z&X-Amz-Expires=300&X-Amz-Signature=a8d6a9e7bd80cb3d2a6f3177f5df63a2361f24ecfdd003aaa7a5672928ddb706&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.4.1-models.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.101.251\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.101.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1965103828 (1.8G) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.4.1-models.tar.gz’\n",
            "\n",
            "deepspeech-0.4.1-mo 100%[===================>]   1.83G  65.9MB/s    in 40s     \n",
            "\n",
            "2019-03-24 17:57:53 (46.4 MB/s) - ‘deepspeech-0.4.1-models.tar.gz’ saved [1965103828/1965103828]\n",
            "\n",
            "models/\n",
            "models/._lm.binary\n",
            "models/lm.binary\n",
            "models/output_graph.rounded.pb\n",
            "models/output_graph.pbmm\n",
            "models/output_graph.pb\n",
            "models/._trie\n",
            "models/trie\n",
            "models/._alphabet.txt\n",
            "models/alphabet.txt\n",
            "models/output_graph.rounded.pbmm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3usRoqb9m_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tESYE8xDMHb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "manuscript=read_csv(\"/content/indian_accent_wav_files/validated.csv\")\n",
        "manuscript.transcript=manuscript.transcript.str.encode(\"utf-8\").apply(lambda txt : re.sub(\"[^a-z ]\",'',txt.decode(\"ascii\",\"ignore\").strip().lower())).tolist()\n",
        "manuscript.wav_filename=manuscript.wav_filename.str.replace(\"/mnt/e/speech_data/mozilla_original_common_voice_05_03_2019/clips/\",\"/content/indian_accent_wav_files/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a7EGS_S5NaEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, validation = train_test_split(manuscript, test_size=0.2)\n",
        "train.to_csv(\"/content/indian_accent_wav_files/train.csv\",index=False)\n",
        "validation.to_csv(\"/content/indian_accent_wav_files/validation.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcruHiMok89b",
        "colab_type": "code",
        "outputId": "5d0c75d6-02f5-4233-a5ca-1f5f079fe4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ls /content/indian_accent_wav_files/*.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/indian_accent_wav_files/*.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pu_R2LDRdSwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99ef12b2-8ae2-462b-f2bb-f87c57d0a9a8"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4fl12g4aEn-i",
        "colab_type": "code",
        "outputId": "ab1ca18f-9419-4b47-9563-14a4d1e0a94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd /content/DeepSpeech/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P4if1-ROBjW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !./DeepSpeech.py --helpfull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOV0yyKGQHJC",
        "colab_type": "code",
        "outputId": "a5574947-2037-4910-88d2-8fbb8bcee4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "!./DeepSpeech.py  --n_hidden 2048  --epoch -31 --train_files /content/indian_accent_wav_files/train.csv --checkpoint_dir /content/models/ --dev_files /content/indian_accent_wav_files/validation.csv --learning_rate 0.0001 --train_batch_size 100 --export_dir /content/deepspeech_modelexport/ --notest --train_cached_features_path /content/train_features_cache/train_features.hdf5 --dev_cached_features_path /content/validation_features_cache/validation_features.hdf5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Preprocessing ['/content/indian_accent_wav_files/train.csv']\n",
            "Saving to /content/train_features_cache/train_features.hdf5\n",
            "Preprocessing done\n",
            "Preprocessing ['/content/indian_accent_wav_files/validation.csv']\n",
            "Saving to /content/validation_features_cache/validation_features.hdf5\n",
            "Preprocessing done\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/rnn/python/ops/lstm_ops.py:696: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "W Parameter --validation_step needs to be >0 for early stopping to work\n",
            "I STARTING Optimization\n",
            "I Training epoch 0...\n",
            "I Training of Epoch 0 - loss: 130.212062\n",
            "100% (132 of 132) |#######################| Elapsed Time: 0:10:27 Time:  0:10:27\n",
            "I Training epoch 1...\n",
            "I Training of Epoch 1 - loss: 122.290861\n",
            "100% (132 of 132) |#######################| Elapsed Time: 0:11:21 Time:  0:11:21\n",
            "I Training epoch 2...\n",
            " 81% (107 of 132) |##################     | Elapsed Time: 0:08:05 ETA:   0:02:36"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYy1KncRH5cT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm  /content/deepspeech_modelexport/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CH8InWgLGEhg",
        "colab_type": "code",
        "outputId": "f2531577-4220-4e6f-f081-fc0c0a3bda48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets init -p /content/deepspeech_modelexport/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Data package template written to: /content/deepspeech_modelexport/dataset-metadata.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "umeYhF-IJzHg",
        "colab_type": "code",
        "outputId": "de6471f9-7050-4442-b509-3f0623315c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "ls /content/deepspeech_modelexport/ -sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 181M\n",
            "4.0K dataset-metadata.json  181M output_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ru4l_HBJ4UY",
        "colab_type": "code",
        "outputId": "b6062d40-0d16-40c0-d219-49748208ac27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "cat /content/deepspeech_modelexport/dataset-metadata.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"licenses\": [\n",
            "    {\n",
            "      \"name\": \"CC0-1.0\"\n",
            "    }\n",
            "  ], \n",
            "  \"id\": \"mohan007/INSERT_SLUG_HERE\", \n",
            "  \"title\": \"INSERT_TITLE_HERE\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFCzbiQIKS2L",
        "colab_type": "code",
        "outputId": "8446f322-76cf-4fa0-9144-a590e91b686d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"/content/deepspeech_modelexport/dataset-metadata.json\",\"r\") as dd:\n",
        "  dct= json.load(dd)\n",
        "  dct['id']='mohan007/deepspeech_exportmodel.0.8'\n",
        "  dct['title']='deeppseechmodel_21_03_2019_22_30'\n",
        "  print(dct)\n",
        "with open(\"/content/deepspeech_modelexport/dataset-metadata.json\",\"w\") as rf:\n",
        "  json.dump(dct,rf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'licenses': [{'name': 'CC0-1.0'}], 'id': 'mohan007/deepspeech_exportmodel.0.8', 'title': 'deeppseechmodel_21_03_2019_22_30'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bMQ5Uw-KJ9bx",
        "colab_type": "code",
        "outputId": "d2c9774b-5411-4744-a509-c0cd13aaaf72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets create -p /content/deepspeech_modelexport/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Starting upload for file output_graph.pb\n",
            "100% 180M/180M [00:07<00:00, 24.9MB/s]\n",
            "Upload successful: output_graph.pb (180MB)\n",
            "Your private Dataset is being created. Please check progress at https://www.kaggle.com/mohan007/deepspeech_exportmodel.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V9vF-z3iKOhw",
        "colab_type": "code",
        "outputId": "d5b188bb-8f87-4623-d1bd-5788bdebe438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "ls /content/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mDeepSpeech\u001b[0m/                     \u001b[34;42mindian_accent_wav_files\u001b[0m/\n",
            "deepspeech-0.4.1-models.tar.gz  installation_script.sh\n",
            "\u001b[01;34mdeepspeech_modelexport\u001b[0m/         \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mIndianAccentSpeechRecognition\u001b[0m/  processedcommonvoice-indianaccents.zip\n",
            "indian_accents.tar.gz           \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9cXLoNfJVpsI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}